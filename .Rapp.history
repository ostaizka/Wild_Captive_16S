NPOMsums <- rowSums(NPOM)#
nRPO <- NPOMsums / sum(NPOMsums)#
nRPO
NPAM
q=0#
if(q=1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM[,1]#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM[,1]#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
q=1#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM[,1]#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
q=2#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM[,1]#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
predator="Predator1"#
q=1#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM[,predator]#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
library(hilldiv)#
hill_div(NPAM,qvalue=1)
gamma_div
evenweight=c(1/3,1/3,1/3)#
pi <- NPAM#
pi.w <- sweep(pi, 2, evenweight, "*")
pi.w
evenweight=c(1/3,1/3,1/3)#
q=1 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM#
pi.w <- sweep(pi, 2, evenweight, "*")#
pi.w.sum <- rowSums(pi.w)#
pi.w.sum.q <- pi.w.sum^q#
basicsum <- sum(pi.w.sum.q)#
basicsum^(1/(1-q))
evenweight=c(1/3,1/3,1/3)#
q=2 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM#
pi.w <- sweep(pi, 2, evenweight, "*")#
pi.w.sum <- rowSums(pi.w)#
pi.w.sum.q <- pi.w.sum^q#
basicsum <- sum(pi.w.sum.q)#
basicsum^(1/(1-q))
gamma_div(NPAM,qvalue=1)
gamma_div(NPAM,qvalue=1,weights=evenweight)
gamma_div(NPAM,qvalue=1,weight=evenweight)
colSums(APAM) / sum(colSums(APAM))
seqdepthweight <- colSums(APAM) / sum(colSums(APAM))#
q=2 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM#
pi.w <- sweep(pi, 2, evenweight, "*")#
pi.w.sum <- rowSums(pi.w)#
pi.w.sum.q <- pi.w.sum^q#
basicsum <- sum(pi.w.sum.q)#
basicsum^(1/(1-q))
seqdepthweight <- colSums(APAM) / sum(colSums(APAM))#
q=2 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM#
pi.w <- sweep(pi, 2, seqdepthweight, "*")#
pi.w.sum <- rowSums(pi.w)#
pi.w.sum.q <- pi.w.sum^q#
basicsum <- sum(pi.w.sum.q)#
basicsum^(1/(1-q))
gamma_div(NPAM,qvalue=1,weight=seqdepthweight)
q=1 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- NPAM#
pi.w <- sweep(pi, 2, seqdepthweight, "*")#
pi.w.sum <- rowSums(pi.w)#
pi.w.sum.q <- pi.w.sum^q#
basicsum <- sum(pi.w.sum.q)#
basicsum^(1/(1-q))
basicsum
pi.w.sum
RPA
pi <- rowSums(NPOM)
pi
q=1 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- RPO#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
q=2 #Can be changed to 0, 2 or any other positive value#
if(q == 1){q=0.999999999} # Because the function is not defined for the unity#
pi <- RPO#
pi.q <- pi^q#
basicsum <- sum(pi.q)#
basicsum^(1/(1-q))
hill_div(to.incidence(APAM),qvalue=1)
hill_div(to.incidence(APAM),qvalue=2)
hill_div(RPO,qvalue=1)
hill_div(RPO,qvalue=2)
APAMsums <- rowSums(APAM)#
RPA <- APAMsums / sum(APAMsums)#
RPA
RPA
APAMsums / sum(APAM)
weights <- read.csv(~/Desktop/chichen_weight.csv)
weights <- read.csv(""~/Desktop/chichen_weight.csv")
weights <- read.csv("~/Desktop/chichen_weight.csv")
weights
weights <- read.csv("~/Desktop/chichen_weight.csv",header=FALSE)
head(weights)
boxplot(V2~V1)
boxplot(V2 ~ V1, data=weights)
library(optparse)#
library(dada2)
bold_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ.tax.final-1.tsv",header=TRUE, row.names=1, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, row.names=1, sep="\t")
head(bold_table)
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, row.names=1, sep="\t")
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")
head(ncbi_table)
duplicates(ncbi_table)
duplicated(ncbi_table)
duplicated(ncbi_table[,1])
nrow(ncbi_table)
ncbi_table <- ncbi_table[duplicated(ncbi_table),]
nrow(ncbi_table)
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]
nrow(ncbi_table)
bold_table <- bold_table[duplicated(bold_table),]
nrow(bold_table)
c(bold_table[,1],ncbi_table[,1])
#Load tables#
bold_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ.tax.final-1.tsv",header=TRUE, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")#
#
#Remove duplicates#
bold_table <- bold_table[duplicated(bold_table),]#
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]
head(bold_table)
bold_table <- bold_table[!duplicated(bold_table),]
head(bold_table)
bold_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ.tax.final-1.tsv",header=TRUE, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")#
#
#Remove duplicates#
bold_table <- bold_table[!duplicated(bold_table),]#
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]
head(bold_table)
c(bold_table[,1],ncbi_table[,1])
c(as.character(bold_table[,1]),as.character(ncbi_table[,1]))
asvlist <- mixedsort(c(as.character(bold_table[,1]),as.character(ncbi_table[,1])))
library(gtools)
asvlist <- mixedsort(c(as.character(bold_table[,1]),as.character(ncbi_table[,1])))
asvlist
nrow(asvlist)
length(asvlist)
asvlist <- mixedsort(unique(c(as.character(bold_table[,1]),as.character(ncbi_table[,1]))))
length(asvlist)
nrow(bold_table)
nrow(ncbi_table)
head(bold_table)
asv="Zotu3317"
bold_table[bold_table$OTU == asv,]
bold_asv <- bold_table[bold_table$OTU == asv,]#
  ncbi_asv <- ncbi_table[ncbi_table$OTU == asv,]
bold_asv
ncbi_asv
bold_asv == ncbi_asv
all(bold_asv == ncbi_asv)
bold_asv
all(bold_asv[c(3:8)] == ncbi_asv[c(3:8)])
bold_asv[,2]
bold_asv[,2] > ncbi_asv[,2]
asv="Zotu2"
bold_asv <- bold_table[bold_table$OTU == asv,]#
  ncbi_asv <- ncbi_table[ncbi_table$OTU == asv,]
bold_asv
ncbi_asv
length(bold_asv)
length(ncbi_asv)
class(bold_asv)
length(c(bold_asv))
c(bold_asv)
c(bold_asv[1,])
bold_asv[1,]
sum(!complete.cases(bold_asv))
sum(complete.cases(bold_asv)
)
complete.cases(bold_asv)
sum(bold_asv =="")
sum(ncbi_asv =="")
asv="X"
bold_asv <- bold_table[bold_table$OTU == asv,]
bold_asv
nrow(bold_asv)
nrow(ncbi_asv)
#Load tables#
bold_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ.tax.final-1.tsv",header=TRUE, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")#
#
#Remove duplicates#
bold_table <- bold_table[!duplicated(bold_table),]#
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]
#Identify ASVs and sort them#
asvlist <- mixedsort(unique(c(as.character(bold_table[,1]),as.character(ncbi_table[,1]))))#
#
#Iterate across ASVs#
for (asv in asvlist){#
  #Subset table#
  bold_asv <- bold_table[bold_table$OTU == asv,]#
  ncbi_asv <- ncbi_table[ncbi_table$OTU == asv,]#
#
  #If BOLD is empty use NCBI#
  if(nrow(bold_asv) == 0){#
  output_asv <- ncbi_asv#
  #If NCBI is empty use BOLD#
  }else if(nrow(ncbi_asv) == 0){#
  output_asv <- bold_asv#
  }else{#
  #If both taxonomies are present:#
    #If taxonomies are identical just print one#
    if(all(bold_asv[c(3:8)] == ncbi_asv[c(3:8)])){#
    output_asv <- bold_asv#
    }else{#
      #If taxonomies are different select the one with highest identity#
      if(bold_asv[,2] > ncbi_asv[,2]){#
      output_asv <- bold_asv#
      }else if(bold_asv[,2] < ncbi_asv[,2]){#
      output_asv <- ncbi_asv#
      }else{#
        #If the identities are identical, select the most complete taxonomy#
        if(sum(bold_asv=="") < sum(ncbi_asv=="")){#
        output_asv <- bold_asv#
        }else if(sum(bold_asv=="") > sum(ncbi_asv=="")){#
        output_asv <- ncbi_asv#
      }else{#
        #If the criteria cannot choose any preferred taxonomy, use BOLD for being better curated#
        output_asv <- bold_asv#
      }#
    }#
  }#
  }#
}
#Load tables#
bold_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ.tax.final-1.tsv",header=TRUE, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ZBJ_nt.tax.final-1.tsv",header=TRUE, sep="\t")#
#
#Remove duplicates#
bold_table <- bold_table[!duplicated(bold_table),]#
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]#
#
#Identify ASVs and sort them#
asvlist <- mixedsort(unique(c(as.character(bold_table[,1]),as.character(ncbi_table[,1]))))#
#
merged_taxonomy <- c()#
#Iterate across ASVs#
for (asv in asvlist){#
  #Subset table#
  bold_asv <- bold_table[bold_table$OTU == asv,]#
  ncbi_asv <- ncbi_table[ncbi_table$OTU == asv,]#
#
  #If BOLD is empty use NCBI#
  if(nrow(bold_asv) == 0){#
  output_asv <- ncbi_asv#
  #If NCBI is empty use BOLD#
  }else if(nrow(ncbi_asv) == 0){#
  output_asv <- bold_asv#
  }else{#
  #If both taxonomies are present:#
    #If taxonomies are identical just print one#
    if(all(bold_asv[c(3:8)] == ncbi_asv[c(3:8)])){#
    output_asv <- bold_asv#
    }else{#
      #If taxonomies are different select the one with highest identity#
      if(bold_asv[,2] > ncbi_asv[,2]){#
      output_asv <- bold_asv#
      }else if(bold_asv[,2] < ncbi_asv[,2]){#
      output_asv <- ncbi_asv#
      }else{#
        #If the identities are identical, select the most complete taxonomy#
        if(sum(bold_asv=="") < sum(ncbi_asv=="")){#
        output_asv <- bold_asv#
        }else if(sum(bold_asv=="") > sum(ncbi_asv=="")){#
        output_asv <- ncbi_asv#
      }else{#
        #If the criteria cannot choose any preferred taxonomy, use BOLD for being better curated#
        output_asv <- bold_asv#
      }#
    }#
  }#
  }#
merged_taxonomy <- rbind(merged_taxonomy,output_asv)#
}
head(merged_taxonomy)
head(merged_taxonomy,50)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv")
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quotes=FALSE)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quote=FALSE)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quote=FALSE,sep="\t")
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quote=FALSE,sep="\t",rownames=TRUE,colnames=TRUE)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quote=FALSE,sep="\t",row.names=TRUE,col.names=TRUE)
head(merged_taxonomy)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ZBJ.merged.tax.tsv",quote=FALSE,sep="\t",row.names=FALSE,col.names=TRUE)
#Load tables#
bold_table <- read.table("/Users/anttonalberdi/Downloads/ANML.tax.final-1.tsv",header=TRUE, sep="\t")#
ncbi_table <- read.table("/Users/anttonalberdi/Downloads/ANML_nt.tax.final-1.tsv",header=TRUE, sep="\t")#
#
#Remove duplicates#
bold_table <- bold_table[!duplicated(bold_table),]#
ncbi_table <- ncbi_table[!duplicated(ncbi_table),]#
#
#Identify ASVs and sort them#
asvlist <- mixedsort(unique(c(as.character(bold_table[,1]),as.character(ncbi_table[,1]))))#
#
merged_taxonomy <- c()#
#Iterate across ASVs#
for (asv in asvlist){#
  #Subset table#
  bold_asv <- bold_table[bold_table$OTU == asv,]#
  ncbi_asv <- ncbi_table[ncbi_table$OTU == asv,]#
#
  #If BOLD is empty use NCBI#
  if(nrow(bold_asv) == 0){#
  output_asv <- ncbi_asv#
  #If NCBI is empty use BOLD#
  }else if(nrow(ncbi_asv) == 0){#
  output_asv <- bold_asv#
  }else{#
  #If both taxonomies are present:#
    #If taxonomies are identical just print one#
    if(all(bold_asv[c(3:8)] == ncbi_asv[c(3:8)])){#
    output_asv <- bold_asv#
    }else{#
      #If taxonomies are different select the one with highest identity#
      if(bold_asv[,2] > ncbi_asv[,2]){#
      output_asv <- bold_asv#
      }else if(bold_asv[,2] < ncbi_asv[,2]){#
      output_asv <- ncbi_asv#
      }else{#
        #If the identities are identical, select the most complete taxonomy#
        if(sum(bold_asv=="") < sum(ncbi_asv=="")){#
        output_asv <- bold_asv#
        }else if(sum(bold_asv=="") > sum(ncbi_asv=="")){#
        output_asv <- ncbi_asv#
      }else{#
        #If the criteria cannot choose any preferred taxonomy, use BOLD for being better curated#
        output_asv <- bold_asv#
      }#
    }#
  }#
  }#
merged_taxonomy <- rbind(merged_taxonomy,output_asv)#
}
write.table("/Users/anttonalberdi/Downloads/ANML.merged.tax.tsv",opt$o,quote=FALSE,sep="\t",row.names=FALSE,col.names=TRUE)
write.table("/Users/anttonalberdi/Downloads/ANML.merged.tax.tsv",quote=FALSE,sep="\t",row.names=FALSE,col.names=TRUE)
write.table(merged_taxonomy,"/Users/anttonalberdi/Downloads/ANML.merged.tax.tsv",quote=FALSE,sep="\t",row.names=FALSE,col.names=TRUE)
~dirFCM1_18.csvdir=
dir="/cliptest/2-Filtered/A/"
filtFs_list <- gsub("_1.fastq","",list.files(path = dir, pattern = "_1.fastq", full.names=TRUE))#
filtRs_list <- gsub("_2.fastq","",list.files(path = dir, pattern = "_2.fastq", full.names=TRUE))#
filtFs_rev_list <- gsub("_1.rev.fastq","",list.files(path = dir, pattern = "_1.rev.fastq", full.names=TRUE))#
filtRs_rev_list <- gsub("_2.rev.fastq","",list.files(path = dir, pattern = "_2.rev.fastq", full.names=TRUE))
filtRs_rev_list
filtFs_list
dir
filtFs_list <- gsub("_1.fastq","",list.files(path = dir, pattern = "_1.fastq", full.names=TRUE))
filtFs_list
list.files(path = dir, pattern = "_1.fastq", full.names=TRUE)
dir
dir="/Users/anttonalberdi/cliptest/2-Filtered/A/"
filtFs_list <- gsub("_1.fastq","",list.files(path = dir, pattern = "_1.fastq", full.names=TRUE))
filtFs_list
filtFs_rev_list <- gsub("_1.rev.fastq","",list.files(path = dir, pattern = "_1.rev.fastq", full.names=TRUE))
filtFs_rev_list
if (setequal(filtFs_list, filtRs_list) == TRUE){#
  filtFs <- paste(filtFs_list,"_1.fastq",sep="")#
  filtRs <- paste(filtFs_list,"_2.fastq",sep="")#
}else if(setequal(filtFs_rev_list, filtRs_rev_list) == TRUE){#
  filtFs <- c(filtFs,paste(filtFs_rev_list,"_1.rev.fastq",sep=""))#
  filtRs <- c(filtRs,paste(filtRs_rev_list,"_1.rev.fastq",sep=""))#
}else{#
  write("ERROR! The forward and reverse reads do not match",file=statsfile,append=TRUE)#
  print("ERROR! The forward and reverse reads do not match")#
}
filtFs <- paste(filtFs_list,"_1.fastq",sep="")#
  filtRs <- paste(filtFs_list,"_2.fastq",sep="")
filtFs <- c(filtFs,paste(filtFs_rev_list,"_1.rev.fastq",sep=""))#
  filtRs <- c(filtRs,paste(filtRs_rev_list,"_1.rev.fastq",sep=""))
filtFs
pattern="fastq"
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtFs <- paste(filtFs_list,paste("_1.",pattern,sep=""),sep="")
filtFs
filtRs <- paste(filtFs_list,paste("_2.",pattern,sep=""),sep="")
filtRs
setequal(filtFs_list, filtRs_list)
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))#
filtRs_list <- gsub(paste("_2.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_2.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtRs_list
setequal(filtFs_list, filtRs_list)
dir
filtFs_list <- gsub(paste("_1.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_1.",pattern,sep=""), full.names=TRUE))#
filtRs_list <- gsub(paste("_2.",pattern,sep=""),"",list.files(path = dir, pattern = paste("_2.",pattern,sep=""), full.names=TRUE))
filtFs_list
filtRs_list
if (setequal(filtFs_list, filtRs_list) == TRUE){#
  filtFs <- paste(filtFs_list,paste("_1.",pattern,sep=""),sep="")#
  filtRs <- paste(filtFs_list,paste("_2.",pattern,sep=""),sep="")#
}else{#
  print("ERROR! The forward and reverse reads do not match")#
}
filtFs
filtRs
paste("_1.",pattern,sep="")
dir="/Users/anttonalberdi/cliptest/3-DADA2"
filelist <- list.files(path = dir, pattern = ".rds", full.names=TRUE)#
SequenceTableList <- lapply(filelist,readRDS)
library(dada2)
trimtablist <- c("A.rev.csv","B.rev.csv","C.csv")
trimtablist[!grepl("rev.csv",trimtablist)]
table <- read.csv("~/Downloads/exercise.csv")
table
table <- read.csv("~/Downloads/exercise.csv",row.names=1,header=TRUE)
table
library(g)
library(hilldiv)
hill_div(table,qvalue=0)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
table <- read.csv("~/Downloads/exercise.csv",row.names=1,header=TRUE)
table
library(hilldiv)
hill_div(table,qvalue=0)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
hill_div(table,qvalue=0.5)
hill_div(table,qvalue=0)
hill_div(table,qvalue=0.1)
hill_div(table,qvalue=0.2)
hill_div(table,qvalue=0.32)
hill_div(table,qvalue=0.4)
hill_div(table,qvalue=0.5)
hill_div(table,qvalue=1)
hill_div(table,qvalue=2)
library(devtools)#
install_github("anttonalberdi/hilldiv")
library(reshape2)#
library(gplots)#
library(ggplot2)
install.packages("gplots")
library(gplots)
library(ggrepel)#
library(purrr)
library(hilldiv)#
library(ape)#
library(phytools)#
library(phylobase)#
library(phylosignal)
install.packages("phylobase")
library(phytools)#
library(phylobase)#
library(phylosignal)#
library(ggplot2)#
library(vegan)#
library(tidyverse)#
library(phytools)
install.packages("phylosignal")
library(phytools)#
library(plyr)#
library(dplyr)#
library(dendextend)#
library(ggpubr)#
library(dmetar)#
library(meta)#
library(metafor)
install.packages("dendextend")
library(TreeDist)
install.packages("TreeDist")
library(reshape2)#
library(gplots)#
library(ggplot2)#
library(ggrepel)#
library(purrr)#
library(hilldiv)#
library(ape)#
library(phytools)#
library(phylobase)#
library(phylosignal)#
library(ggplot2)#
library(vegan)#
library(tidyverse)#
library(phytools)#
library(plyr)#
library(dplyr)#
library(dendextend)#
library(ggpubr)#
library(dmetar)#
library(meta)#
library(metafor)#
library(TreeDist)
setwd("~/github/Wild_Captive_16S")
metadata.filtered <- read.table("Data/metadata.filtered.csv", sep =";",row.names=1)#
code.list <- as.character(read.table("Data/sp_code.txt")[,1])#
capwild.tree <- read.tree("Data/genustree.tre")
betadis_dR_results <- c()#
for (code in code.list){#
  final.table <- read.table(paste("Tables/countfiltered_",code,".tsv",sep=""))#
  ##Filter the metadata#
  metadata.filtered.subset <- metadata.filtered[which(metadata.filtered[,1] %in% colnames(final.table)),]#
  #Check whether both lists are identical#
  identical(sort(colnames(final.table)),sort(as.character(metadata.filtered.subset[,"Sample"])))#
  divpart.dR <- div_part(final.table,qvalue=0,hierarchy=metadata.filtered.subset[,c("Sample","Origin")])#
  betadis.dR <- beta_dis(divpart.dR)#
  betadis_dR_results <- append(betadis_dR_results,betadis.dR$UqN[2])#
}#
names(betadis_dR_results) <- code.list#
#
#Statistics#
mean(betadis_dR_results)#
sd(betadis_dR_results)#
max(betadis_dR_results)#
min(betadis_dR_results)
betadis_dR_results
cbind(betadis_dR_results,betadis_dRE_results,betadis_dRER_results)
betadis_dRE_results <- c()#
for (code in code.list){#
  final.table <- read.table(paste("Tables/countfiltered_",code,".tsv",sep=""))#
  ##Filter the metadata#
  metadata.filtered.subset <- metadata.filtered[which(metadata.filtered[,1] %in% colnames(final.table)),]#
  #Check whether both lists are identical#
  identical(sort(colnames(final.table)),sort(as.character(metadata.filtered.subset[,"Sample"])))#
  divpart.dRE <- div_part(final.table,qvalue=1,hierarchy=metadata.filtered.subset[,c("Sample","Origin")])#
  betadis.dRE <- beta_dis(divpart.dRE)#
  betadis_dRE_results <- append(betadis_dRE_results,betadis.dRE$UqN[2])#
}#
names(betadis_dRE_results) <- code.list#
#
#Statistics#
mean(betadis_dRE_results)#
sd(betadis_dRE_results)#
max(betadis_dRE_results)#
min(betadis_dRE_results)#
#
###
## B6.3) Diversity partitioning based on richness+eveness+regularity (dRER)#
###
#
betadis_dRER_results <- c()#
for (code in code.list){#
  final.table <- read.table(paste("Tables/countfiltered_",code,".tsv",sep=""))#
  ##Filter the metadata#
  metadata.filtered.subset <- metadata.filtered[which(metadata.filtered[,1] %in% colnames(final.table)),]#
  #Check whether both lists are identical#
  identical(sort(colnames(final.table)),sort(as.character(metadata.filtered.subset[,"Sample"])))#
  tree_filtered <- match_data(final.table,capwild.tree,output="tree")#
  divpart.dRER <- div_part(final.table,qvalue=1,hierarchy=metadata.filtered.subset[,c("Sample","Origin")],tree=tree_filtered)#
  betadis.dRER <- beta_dis(divpart.dRER)#
  betadis_dRER_results <- append(betadis_dRER_results,betadis.dRER$UqN[2])#
}#
names(betadis_dRER_results) <- code.list#
#
#Statistics#
mean(betadis_dRER_results)#
sd(betadis_dRER_results)#
max(betadis_dRER_results)#
min(betadis_dRER_results)#
#
#Join results#
cbind(betadis_dR_results,betadis_dRE_results,betadis_dRER_results)
write.table(betadis_results,"summary_betadis.tsv",sep="\t")
betadis_results <- cbind(betadis_dR_results,betadis_dRE_results,betadis_dRER_results)#
write.table(betadis_results,"summary_betadis.tsv",sep="\t")
host_tree <- read.nexus("Data/host_phylogeny.tre")#
#
#Load metanalysis results#
meta_dR.raw <- readRDS("Results/RDS/meta_dR.all.RData")#
meta_dRE.raw <- readRDS("Results/RDS/meta_dRE.all.RData")#
meta_dRER.raw <- readRDS("Results/RDS/meta_dRER.all.RData")#
results <- data.frame(dR=meta_dR.raw$TE,dRE=meta_dRE.raw$TE,dRER=meta_dRER.raw$TE)#
rownames(results) <- meta_dR.raw$studlab
results
results <- read.table("Results/summary_betadis.tsv")
results
tree4d <-phylo4d(host_tree, tip.data = results)
host_tree <- read.nexus("Data/host_phylogeny.tre")
host_tree
host_tree <- read.tree("Data/host_phylogeny.tre")
host_tree
tree4d <-phylo4d(host_tree, tip.data = results)
phyloSignal(tree4d, methods = "Cmean", reps = 9999, W = NULL)
library(phylosignal)
install.packages("sf")
library(phylosignal)
phyloSignal(tree4d, methods = "Cmean", reps = 9999, W = NULL)
betadis_dR_results <- c()#
for (code in code.list){#
  final.table <- read.table(paste("Tables/countfiltered_",code,".tsv",sep=""))#
  ##Filter the metadata#
  metadata.filtered.subset <- metadata.filtered[which(metadata.filtered[,1] %in% colnames(final.table)),]#
  #Check whether both lists are identical#
  identical(sort(colnames(final.table)),sort(as.character(metadata.filtered.subset[,"Sample"])))#
  divpart.dR <- div_part(final.table,qvalue=0,hierarchy=metadata.filtered.subset[,c("Sample","Origin")])#
  betadis.dR <- beta_dis(divpart.dR)#
  betadis_dR_results <- append(betadis_dR_results,betadis.dR$SqN[2])#
}#
names(betadis_dR_results) <- code.list#
#
#Statistics#
mean(betadis_dR_results)#
sd(betadis_dR_results)#
max(betadis_dR_results)#
min(betadis_dR_results)
betadis_dR_results <- c()#
for (code in code.list){#
  final.table <- read.table(paste("Tables/countfiltered_",code,".tsv",sep=""))#
  ##Filter the metadata#
  metadata.filtered.subset <- metadata.filtered[which(metadata.filtered[,1] %in% colnames(final.table)),]#
  #Check whether both lists are identical#
  identical(sort(colnames(final.table)),sort(as.character(metadata.filtered.subset[,"Sample"])))#
  divpart.dR <- div_part(final.table,qvalue=0,hierarchy=metadata.filtered.subset[,c("Sample","Origin")])#
  betadis.dR <- beta_dis(divpart.dR)#
  betadis_dR_results <- append(betadis_dR_results,betadis.dR$UqN[2])#
}#
names(betadis_dR_results) <- code.list#
#
#Statistics#
mean(betadis_dR_results)#
sd(betadis_dR_results)#
max(betadis_dR_results)#
min(betadis_dR_results)
betadis_dR_results
betadis_dRER_results
mean(betadis_dRE_results)#
sd(betadis_dRE_results)#
max(betadis_dRE_results)#
min(betadis_dRE_results)
mean(betadis_dRER_results)#
sd(betadis_dRER_results)#
max(betadis_dRER_results)#
min(betadis_dRER_results)
#Subset diversity table#
summary_dRER <- read.table("Results/summary_diversity_dRE.tsv")#
sublist1 <- c("RHBR","PYNE","PAAN","PATR","GOGO")#
summary_dRER.subset1 <- summary_dRER[rownames(summary_dRER) %in% sublist1,]#
#
#Run meta-analysis#
meta_dRER_sub1_ready <- tibble::rownames_to_column(summary_dRER.subset1,"Author")#
rownames(meta_dRER_sub1_ready) <- meta_dRER_sub1_ready$Author#
meta_dRER_sub1_ready <- meta_dRER_sub1_ready[sublist1,]#
meta_dRER_sub1.raw <- metacont(n_captive,mean_captive,sd_captive,n_wild,mean_wild,sd_wild,#
                                 data = meta_dRER_sub1_ready,#
                                 studlab = paste(Author),#
                                 comb.fixed = FALSE,#
                                 comb.random = TRUE,#
                                 method.tau = "SJ",#
                                 hakn = TRUE,#
                                 prediction = TRUE,#
                                 sm = "SMD")#
#
saveRDS(meta_dRER_sub1.raw,"Results/RDS/meta_dRE.primates.RData")
meta_dRER_sub1.raw
summary_dRER <- read.table("Results/summary_diversity_dRE.tsv")#
sublist2 <- c("TUTR","MOCH","BOGA","ELDA","CENI")#
summary_dRER.subset2 <- summary_dRER[rownames(summary_dRER) %in% sublist2,]#
#
#Run meta-analysis#
meta_RER_sub2_ready <- tibble::rownames_to_column(summary_dRER.subset2,"Author")#
rownames(meta_RER_sub2_ready) <- meta_RER_sub2_ready$Author#
meta_RER_sub2_ready <- meta_RER_sub2_ready[sublist2,]#
meta_RER_sub2.raw <- metacont(n_captive,mean_captive,sd_captive,n_wild,mean_wild,sd_wild,#
                                 data = meta_RER_sub2_ready,#
                                 studlab = paste(Author),#
                                 comb.fixed = FALSE,#
                                 comb.random = TRUE,#
                                 method.tau = "SJ",#
                                 hakn = TRUE,#
                                 prediction = TRUE,#
                                 sm = "SMD")#
#
saveRDS(meta_RER_sub2.raw,"Results/RDS/meta_dRE.cetartiodactyla.RData")
meta_RER_sub2.raw
summary_dRE <- read.table("Results/summary_diversity_dRE.tsv")#
summary_dRE <- as.data.frame(summary_dRE)#
meta_dRE_ready <- tibble::rownames_to_column(summary_dRE,"Author")#
rownames(meta_dRE_ready) <- meta_dRE_ready$Author#
sp_sorted <- c("VAHI","APIB","RADY","CHMY","ALGI","SHCR","RHBR","PYNE","PAAN","PATR","GOGO","PEMA","PELE","TUTR","MOCH","BOGA","ELDA","CENI","EQKI","AIME","PATI","MYTR","SAHA1","SAHA2","LALT")#
meta_dRE_ready <- meta_dRE_ready[sp_sorted,]#
meta_dRE.raw <- metacont(n_captive,mean_captive,sd_captive,n_wild,mean_wild,sd_wild,#
                      data = meta_dRE_ready,#
                      studlab = paste(Author),#
                      comb.fixed = FALSE,#
                      comb.random = TRUE,#
                      method.tau = "SJ",#
                      hakn = TRUE,#
                      prediction = TRUE,#
                      sm = "SMD")#
saveRDS(meta_dRE.raw, "Results/RDS/meta_dRE.all.RData")
meta_dRE.raw
meta_dR.raw <- readRDS("Results/RDS/meta_dR.all.RData")
meta_dR.raw
meta_dR.raw <- readRDS("Results/RDS/meta_dR.all.RData")#
meta_dRE.raw <- readRDS("Results/RDS/meta_dRE.all.RData")#
meta_dRER.raw <- readRDS("Results/RDS/meta_dRER.all.RData")#
results <- data.frame(dR=meta_dR.raw$TE,dRE=meta_dRE.raw$TE,dRER=meta_dRER.raw$TE)#
rownames(results) <- meta_dR.raw$studlab#
#
#Create phylo4d object#
tree4d <-phylo4d(host_tree, tip.data = results)#
#
#Run phylogenetic signal analysis#
phyloSignal(tree4d, methods = "Cmean", reps = 9999, W = NULL)
